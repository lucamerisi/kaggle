{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1kc4zYJu-IWNNlQNPVyvQRYGOGIWbMOJw","authorship_tag":"ABX9TyO7MjY7baBb9UMAzNluM9xu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"5DRsgG2tJpym"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split\n","!cp /content/drive/MyDrive/2-folder/kaggle/df_utils.py /content/\n","!cp /content/drive/MyDrive/2-folder/kaggle/nn_utils.py /content/\n","import df_utils\n","import nn_utils"]},{"cell_type":"code","source":["df_train_loaded = pd.read_csv('/content/drive/MyDrive/2-folder/kaggle/housing-prices-competition/train.csv')\n","df_test_loaded = pd.read_csv('/content/drive/MyDrive/2-folder/kaggle/housing-prices-competition/test.csv')\n","print(f\"df_train_loaded = {df_train_loaded.shape}, df_test_loaded = {df_test_loaded.shape}\")\n","\n","# num_col = len(df_train.columns)\n","# print(f\"num_col = {num_col}\")\n","# print(df_train[\"SalePrice\"][:5])\n","\n","df_train = df_train_loaded.drop(['Id'], axis=1)\n","df_test = df_test_loaded.drop(['Id'], axis=1)\n","\n","# Drop all columns with with more than 20% of missing values\n","df_utils.drop_col_miss_val(df_train, df_test, 20)\n","\n","# Fix categorical values and missing values\n","df_train, df_test = df_utils.prepare_df(df_train, df_test, 5, ['SalePrice'])\n","# print(df_train)\n","\n","# Calculate the correlation of features with the target\n","correlation = df_train.corr()\n","sorted_corr = correlation['SalePrice'].sort_values(ascending=False)\n","# print(sorted_corr)\n","columns = []\n","for i, v in sorted_corr.items():\n","  if v > 0.2 and i != 'SalePrice':\n","    # print('index: ', i, 'value: ', v)\n","    columns.append(i)\n","# print(columns)\n","\n","# Remove target label from training set\n","y_train = df_train['SalePrice'].values\n","# print(y[0:5])\n","df_train = df_train.drop(['SalePrice'], axis=1)\n","\n","# Extract columns with high correlaton\n","df_train = df_train[columns]\n","df_test = df_test[columns]\n","# print(len(df_train.columns))\n","# print(len(df_test.columns))\n","# print(df_train.head(5))\n","\n","# normalize dataframe\n","mean = df_train.mean()\n","std = df_train.std()\n","df_train=(df_train-mean)/std\n","df_test=(df_test-mean)/std\n","\n","X = df_train.values\n","y = y_train\n","\n","# create train, validation and test splits\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)\n","print(f\"X_train = {X_train.shape}, y_train = {y_train.shape}\")\n","print(f\"X_val = {X_val.shape}, y_val = {y_val.shape}\")\n","print(f\"X_test = {X_test.shape}, y_test = {y_test.shape}\")"],"metadata":{"id":"ijRZBnLHKGVF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1736158387490,"user_tz":-60,"elapsed":982,"user":{"displayName":"L","userId":"12971862049250805533"}},"outputId":"7cf0f515-1aef-473d-cb2b-8776032e0513"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["df_train_loaded = (1460, 81), df_test_loaded = (1459, 80)\n","X_train = (876, 36), y_train = (876,)\n","X_val = (292, 36), y_val = (292,)\n","X_test = (292, 36), y_test = (292,)\n"]}]},{"cell_type":"code","source":["# Convert data to PyTorch tensors\n","X_train_t = torch.tensor(X_train, dtype=torch.float32)\n","y_train_t = torch.tensor(y_train, dtype=torch.float32)\n","\n","X_val_t = torch.tensor(X_val, dtype=torch.float32)\n","y_val_t = torch.tensor(y_val, dtype=torch.float32)\n","\n","X_test_t = torch.tensor(X_test, dtype=torch.float32)\n","y_test_t = torch.tensor(y_test, dtype=torch.float32)\n","\n","# Define the model\n","class RegressionModel(nn.Module):\n","    def __init__(self, input_dim):\n","        super(RegressionModel, self).__init__()\n","        self.fc1 = nn.Linear(input_dim, 64)\n","        self.fc2 = nn.Linear(64, 32*4)\n","        self.fc3 = nn.Linear(32*4, 32*4)\n","        self.fc4 = nn.Linear(32*4, 1)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        x = self.relu(self.fc1(x))\n","        x = self.relu(self.fc2(x))\n","        x = self.relu(self.fc3(x))\n","        x = self.fc4(x)\n","        return x\n","\n","input_dim = X_train_t.shape[1]\n","model_0 = RegressionModel(input_dim)\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model_0.parameters(), lr=0.001)\n","\n","nn_utils.training_loop(10000, 30, model_0, criterion, optimizer, X_train_t, y_train_t, X_val_t, y_val_t)\n","\n","model_0.eval()\n","with torch.no_grad():\n","  model_0_preds = model_0(X_val_t).squeeze()\n","print(f\"model_0_preds {type(model_0_preds)} {model_0_preds.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":599},"id":"0sA-42ykHKw4","executionInfo":{"status":"error","timestamp":1736158914123,"user_tz":-60,"elapsed":237621,"user":{"displayName":"L","userId":"12971862049250805533"}},"outputId":"c3305f31-7e1a-4a5b-8ff9-dde9ad04d345"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [200/10000], Train Loss: 9564741632.0000, Test Loss: 1788263040.0000\n","Epoch [400/10000], Train Loss: 434878880.0000, Test Loss: 1573952896.0000\n","Epoch [600/10000], Train Loss: 559769728.0000, Test Loss: 1365901056.0000\n","Epoch [800/10000], Train Loss: 164789184.0000, Test Loss: 1079301888.0000\n","Epoch [1000/10000], Train Loss: 234852624.0000, Test Loss: 1256705280.0000\n","Epoch [1200/10000], Train Loss: 176006592.0000, Test Loss: 1233879040.0000\n","Epoch [1400/10000], Train Loss: 94751456.0000, Test Loss: 1381570048.0000\n","Epoch [1600/10000], Train Loss: 86518432.0000, Test Loss: 1308227072.0000\n","Epoch [1800/10000], Train Loss: 241945712.0000, Test Loss: 1308553216.0000\n","Epoch [2000/10000], Train Loss: 184578048.0000, Test Loss: 1497323264.0000\n","Epoch [2200/10000], Train Loss: 211054208.0000, Test Loss: 1583749760.0000\n","Epoch [2400/10000], Train Loss: 361096736.0000, Test Loss: 1505456896.0000\n","Epoch [2600/10000], Train Loss: 385944320.0000, Test Loss: 1518869248.0000\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-4-c58da097f880>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mnn_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mmodel_0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/nn_utils.py\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(epochs, batch_size, model, criterion, optimizer, X_train_t, y_train_t, X_val_t, y_val_t)\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;31m# Evaluate on the test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    485\u001b[0m                             )\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"differentiable\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dynamo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_break\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    221\u001b[0m             )\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m             adam(\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0mparams_with_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mmaybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdisabled_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_fallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    782\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_single_tensor_adam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 784\u001b[0;31m     func(\n\u001b[0m\u001b[1;32m    785\u001b[0m         \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    430\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction2_sqrt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m             \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcdiv_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdenom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstep_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m         \u001b[0;31m# Lastly, switch back to complex view\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["class HousePricePredictor(nn.Module):\n","    def __init__(self, input_size):\n","        super(HousePricePredictor, self).__init__()\n","        self.fc1 = nn.Linear(input_size, 128)\n","        self.fc2 = nn.Linear(128, 64)\n","        self.fc3 = nn.Linear(64, 1)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        x = self.relu(self.fc1(x))\n","        x = self.relu(self.fc2(x))\n","        x = self.fc3(x)  # No activation for regression\n","        return x\n","\n","input_size = X_train_t.shape[1]  # Number of features\n","model_1 = HousePricePredictor(input_size)\n","\n","# Loss and optimizer\n","criterion = nn.MSELoss()\n","optimizer = optim.Adam(model_1.parameters(), lr=0.01)\n","\n","nn_utils.training_loop(800, 30, model_1, criterion, optimizer, X_train_t, y_train_t, X_val_t, y_val_t)\n","\n","model_1.eval()\n","with torch.no_grad():\n","  model_1_preds = model_1(X_val_t).squeeze()\n","print(f\"model_0_preds {type(model_1_preds)} {model_1_preds.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XuhDoZY81Js6","executionInfo":{"status":"ok","timestamp":1736065869136,"user_tz":-60,"elapsed":49703,"user":{"displayName":"L","userId":"12971862049250805533"}},"outputId":"fbd5a65e-b1d6-4d4b-cb7b-8bad400c4699"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [200/800], Train Loss: 188671296.0000, Test Loss: 978553600.0000\n","Epoch [400/800], Train Loss: 74088672.0000, Test Loss: 1028306496.0000\n","Epoch [600/800], Train Loss: 115633952.0000, Test Loss: 1040427776.0000\n","Epoch [800/800], Train Loss: 181309328.0000, Test Loss: 1219121152.0000\n","model_0_preds <class 'torch.Tensor'> torch.Size([292])\n"]}]},{"cell_type":"code","source":["# t1 = torch.tensor([1, 2, 3])\n","# print(t1)\n","\n","# t2 = torch.tensor([4, 5, 6])\n","# print(t2)\n","\n","# t3 = torch.stack((t1, t2), -1)\n","# print(t3)\n","# print(t3.shape)\n","\n","X_train_meta = torch.stack((model_0_preds, model_1_preds), -1)\n","print(X_train_meta.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cot2UrkV3cI-","executionInfo":{"status":"ok","timestamp":1736065869136,"user_tz":-60,"elapsed":4,"user":{"displayName":"L","userId":"12971862049250805533"}},"outputId":"4615fda3-9379-4d92-dc90-e50e935d81a9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([292, 2])\n"]}]},{"cell_type":"code","source":["class RegressionNN(nn.Module):\n","    def __init__(self, input_dim):\n","        super(RegressionNN, self).__init__()\n","        self.fc1 = nn.Linear(input_dim, 64)\n","        self.fc2 = nn.Linear(64, 32*4)\n","        self.fc3 = nn.Linear(32*4, 32*4)\n","        self.fc4 = nn.Linear(32*4, 1)\n","        self.relu = nn.ReLU()\n","\n","    def forward(self, x):\n","        x = self.relu(self.fc1(x))\n","        x = self.relu(self.fc2(x))\n","        x = self.relu(self.fc3(x))\n","        x = self.fc4(x)\n","        return x\n","\n","input_size = X_train_meta.shape[1]  # Number of features\n","meta_model = RegressionNN(input_size)\n","\n","# Define loss function and optimizer\n","criterion = nn.MSELoss()  # Mean Squared Error Loss\n","optimizer = optim.Adam(meta_model.parameters(), lr=0.0001)\n","\n","nn_utils.training_loop(8000, 30, meta_model, criterion, optimizer, X_train_meta, y_val_t)\n","\n","# model_1.eval()\n","# with torch.no_grad():\n","#   model_1_preds = model_1(X_val_t).squeeze()\n","# print(f\"model_0_preds {type(model_1_preds)} {model_1_preds.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":582},"id":"5KfF8rIdX_vK","executionInfo":{"status":"error","timestamp":1736067616979,"user_tz":-60,"elapsed":195741,"user":{"displayName":"L","userId":"12971862049250805533"}},"outputId":"4f501361-6e14-4241-e16f-595e89ff224d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [200/8000], Train Loss: 257312736.0000\n","Epoch [400/8000], Train Loss: 3136257.2500\n","Epoch [600/8000], Train Loss: 169960736.0000\n","Epoch [800/8000], Train Loss: 79578680.0000\n","Epoch [1000/8000], Train Loss: 263503376.0000\n","Epoch [1200/8000], Train Loss: 122281704.0000\n","Epoch [1400/8000], Train Loss: 1559606144.0000\n","Epoch [1600/8000], Train Loss: 181266592.0000\n","Epoch [1800/8000], Train Loss: 1978906624.0000\n","Epoch [2000/8000], Train Loss: 2213876992.0000\n","Epoch [2200/8000], Train Loss: 154152624.0000\n","Epoch [2400/8000], Train Loss: 239357360.0000\n","Epoch [2600/8000], Train Loss: 448164928.0000\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-e00e195cf942>\u001b[0m in \u001b[0;36m<cell line: 24>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mnn_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train_meta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# model_1.eval()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/nn_utils.py\u001b[0m in \u001b[0;36mtraining_loop\u001b[0;34m(epochs, batch_size, model, criterion, optimizer, X_train_t, y_train_t, X_val_t, y_val_t)\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;31m# Backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_tensor_or_tensors_to_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 340\u001b[0;31m     \u001b[0mgrad_tensors_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_grads_batched\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    341\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                     \u001b[0mout_numel_is_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mout_numel_is_1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                     raise RuntimeError(\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}