{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1kc4zYJu-IWNNlQNPVyvQRYGOGIWbMOJw","authorship_tag":"ABX9TyMXASBlYcPu/VBWiqz8m0jk"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"5DRsgG2tJpym","executionInfo":{"status":"ok","timestamp":1735656509153,"user_tz":-60,"elapsed":4705,"user":{"displayName":"L","userId":"12971862049250805533"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split\n","!cp /content/drive/MyDrive/2-folder/kaggle/df_utils.py /content/\n","import df_utils"]},{"cell_type":"code","source":["df_train_loaded = pd.read_csv('/content/drive/MyDrive/2-folder/kaggle/housing-prices-competition/train.csv')\n","df_test_loaded = pd.read_csv('/content/drive/MyDrive/2-folder/kaggle/housing-prices-competition/test.csv')\n","\n","# num_col = len(df_train.columns)\n","# print(f\"num_col = {num_col}\")\n","# print(df_train[\"SalePrice\"][:5])\n","\n","df_train = df_train_loaded.drop(['Id'], axis=1)\n","df_test = df_test_loaded.drop(['Id'], axis=1)\n","\n","# Drop all columns with with more than 20% of missing values\n","df_utils.drop_col_miss_val(df_train, df_test, 20)\n","\n","# Fix categorical values and missing values\n","df_train, df_test = df_utils.prepare_df(df_train, df_test, 5, ['SalePrice'])\n","# print(df_train)\n","\n","# Calculate the correlation of features with the target\n","correlation = df_train.corr()\n","sorted_corr = correlation['SalePrice'].sort_values(ascending=False)\n","# print(sorted_corr)\n","columns = []\n","for i, v in sorted_corr.items():\n","  if v > 0.2 and i != 'SalePrice':\n","    # print('index: ', i, 'value: ', v)\n","    columns.append(i)\n","# print(columns)\n","\n","# Remove target label from training set\n","y_train = df_train['SalePrice'].values\n","# print(y[0:5])\n","df_train = df_train.drop(['SalePrice'], axis=1)\n","\n","# Extract columns with high correlaton\n","df_train = df_train[columns]\n","df_test = df_test[columns]\n","# print(len(df_train.columns))\n","# print(len(df_test.columns))\n","# print(df_train.head(5))\n","\n","# normalize dataframe\n","df_train=(df_train-df_train.mean())/df_train.std()\n","df_test=(df_test-df_test.mean())/df_test.std()\n","\n","# create X and y for training\n","X = df_train.values\n","y = y_train\n","\n","# create train, validation and test splits\n","# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","# X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"],"metadata":{"id":"ijRZBnLHKGVF","executionInfo":{"status":"ok","timestamp":1735656541798,"user_tz":-60,"elapsed":678,"user":{"displayName":"L","userId":"12971862049250805533"}}},"execution_count":2,"outputs":[]}]}