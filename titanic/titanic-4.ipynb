{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1WLiJwxLXRIQrkg9uZiwULL6ZR744y9MW","authorship_tag":"ABX9TyPrQhIxBeqJU4jeASYrmsrm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":6,"metadata":{"id":"pfmpgBmLwkvV","executionInfo":{"status":"ok","timestamp":1734982136419,"user_tz":-60,"elapsed":7314,"user":{"displayName":"L","userId":"12971862049250805533"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"03608281-bece-4a91-c11a-10d5f7027709"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.1.3)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.26.4)\n","Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost) (2.23.4)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.13.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.6.0)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n"]}],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","!pip install --upgrade xgboost\n","!pip install --upgrade scikit-learn\n","import xgboost as xgb\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split\n","!cp /content/drive/MyDrive/2-folder/kaggle/df_utils.py /content/\n","import df_utils"]},{"cell_type":"code","source":["def preprocess(df):\n","    df = df.copy()\n","\n","    # def normalize_name(x):\n","    #     return \" \".join([v.strip(\",()[].\\\"'\") for v in x.split(\" \")])\n","\n","    def ticket_number(x):\n","        return x.split(\" \")[-1]\n","\n","    def ticket_item(x):\n","        items = x.split(\" \")\n","        if len(items) == 1:\n","            return \"NONE\"\n","        return \"_\".join(items[0:-1])\n","\n","    # df[\"Name\"] = df[\"Name\"].apply(normalize_name)\n","    df[\"Ticket_number\"] = df[\"Ticket\"].apply(ticket_number)\n","    df[\"Ticket_item\"] = df[\"Ticket\"].apply(ticket_item)\n","    return df"],"metadata":{"id":"H6Qg9Zrh1UwN","executionInfo":{"status":"ok","timestamp":1734981809376,"user_tz":-60,"elapsed":262,"user":{"displayName":"L","userId":"12971862049250805533"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["df_train = pd.read_csv('/content/drive/MyDrive/2-folder/kaggle/titanic/train.csv')\n","print(df_train.head(5))\n","\n","# df_train['FamilySize'] = df_train['SibSp'] + df_train['Parch']\n","# df_train['IsAlone'] = (df_train['FamilySize'] == 0).astype(int)\n","# df_train['Title'] = df_train['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n","# common_titles = ['Mr', 'Miss', 'Mrs', 'Master']\n","# df_train['Title'] = df_train['Title'].apply(lambda x: x if x in common_titles else 'Other')\n","# title_map = {'Mr': 0, 'Miss': 1, 'Mrs': 2, 'Master': 3, 'Other': 4}\n","# df_train['Title'] = df_train['Title'].map(title_map)\n","# print(df_train.head(5))\n","\n","df_train_x = df_train.drop(['PassengerId', 'Name', 'Cabin'], axis=1)\n","\n","# Categorical values to numeric\n","df_train_x = df_utils.one_hot_encoding(df_train_x, \"Sex\")\n","label_encoder = preprocessing.LabelEncoder()\n","df_train_x['Embarked']= label_encoder.fit_transform(df_train_x['Embarked'])\n","\n","df_train_x = preprocess(df_train_x)\n","df_train_x = df_train_x.drop(['Ticket'], axis=1)\n","df_train_x['Ticket_item']= label_encoder.fit_transform(df_train_x['Ticket_item'])\n","df_train_x.Ticket_number = pd.to_numeric(df_train_x.Ticket_number, errors='coerce')\n","\n","df_train_x = df_train_x.dropna()\n","df_train_x = df_train_x.reset_index(drop=True)\n","\n","# Fix NaN\n","# print(df_train_x.isna().any())\n","# df_utils.fill_with_mean(\"Age\", df_train_x)\n","# df_utils.fill_with_mode(\"Embarked\", df_train_x)\n","# df_utils.fill_with_mean(\"Ticket_number\", df_train_x)\n","\n","# print(f\"df_train_x.shape[0] = {df_train_x.shape[0]}\")\n","# print(df_train_x.head(10))\n","\n","# ----------------------------------------------------------------\n","\n","y = df_train_x['Survived'].values\n","# print(y[0:5])\n","df_train_x = df_train_x.drop(['Survived'], axis=1)\n","\n","# normalize dataframe\n","# df_train_x=(df_train_x-df_train_x.mean())/df_train_x.std()\n","\n","X = df_train_x.values  #.astype(float)\n","# print(X[0:5])\n","\n","X_trainset, X_testset, y_trainset, y_testset = train_test_split(X, y, test_size=0.1, random_state=3)\n","print('Shape of X training set {}'.format(X_trainset.shape),'&',' Size of Y training set {}'.format(y_trainset.shape))\n","print('Shape of X test set {}'.format(X_testset.shape),'&','Size of y test set {}'.format(y_testset.shape))\n","\n","# Addestra il modello\n","dtrain = xgb.DMatrix(X_trainset, label=y_trainset)\n","params = {\n","    'objective': 'binary:logistic',\n","    'eval_metric': 'logloss'\n","}\n","model = xgb.train(params, dtrain, num_boost_round=100)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ExCQRc-j1msz","executionInfo":{"status":"ok","timestamp":1734982377352,"user_tz":-60,"elapsed":208,"user":{"displayName":"L","userId":"12971862049250805533"}},"outputId":"dbd32413-6b97-4042-9834-4b88d2a150a7"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["   PassengerId  Survived  Pclass  \\\n","0            1         0       3   \n","1            2         1       1   \n","2            3         1       3   \n","3            4         1       1   \n","4            5         0       3   \n","\n","                                                Name     Sex   Age  SibSp  \\\n","0                            Braund, Mr. Owen Harris    male  22.0      1   \n","1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n","2                             Heikkinen, Miss. Laina  female  26.0      0   \n","3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n","4                           Allen, Mr. William Henry    male  35.0      0   \n","\n","   Parch            Ticket     Fare Cabin Embarked  \n","0      0         A/5 21171   7.2500   NaN        S  \n","1      0          PC 17599  71.2833   C85        C  \n","2      0  STON/O2. 3101282   7.9250   NaN        S  \n","3      0            113803  53.1000  C123        S  \n","4      0            373450   8.0500   NaN        S  \n","Shape of X training set (639, 10) &  Size of Y training set (639,)\n","Shape of X test set (71, 10) & Size of y test set (71,)\n"]}]},{"cell_type":"code","source":["df_test = pd.read_csv('/content/drive/MyDrive/2-folder/kaggle/titanic/test.csv')\n","#print(df_train.head(10))\n","\n","df_test_x = df_test.drop(['PassengerId', 'Name', 'Cabin'], axis=1)\n","\n","# Categorical values to numeric\n","df_test_x = df_utils.one_hot_encoding(df_test_x, \"Sex\")\n","label_encoder = preprocessing.LabelEncoder()\n","df_test_x['Embarked']= label_encoder.fit_transform(df_test_x['Embarked'])\n","\n","df_test_x = preprocess(df_test_x)\n","df_test_x = df_test_x.drop(['Ticket'], axis=1)\n","df_test_x['Ticket_item']= label_encoder.fit_transform(df_test_x['Ticket_item'])\n","df_test_x.Ticket_number = pd.to_numeric(df_test_x.Ticket_number, errors='coerce')\n","\n","# Fix NaN\n","# print(df_test_x.isna().any())\n","df_utils.fill_with_mean(\"Age\", df_test_x)\n","df_utils.fill_with_mean(\"Fare\", df_test_x)\n","\n","# print(f\"df_test_x.shape[0] = {df_test_x.shape[0]}\")\n","print(df_test_x.head(10))\n","\n","# normalize dataframe\n","# df_test_x=(df_test_x-df_test_x.mean())/df_test_x.std()\n","\n","X = df_test_x.values  #.astype(float)\n","print(X[0:5])\n","\n","X = xgb.DMatrix(X)\n","y_ = model.predict(X)\n","print(y_[0:5])\n","\n","y_ = y_ > 0.5\n","print(y_[:5])\n","y_ = [1 if a_ > 0.5 else 0 for a_ in y_]\n","print(y_[:5])\n","\n","predictions = pd.DataFrame({\n","        \"PassengerId\": df_test[\"PassengerId\"],\n","        \"Survived\": y_\n","    })\n","\n","def make_submission(predictions):\n","    path=\"/content/drive/MyDrive/2-folder/kaggle/titanic/submission.csv\"\n","    predictions.to_csv(path, index=False)\n","    print(f\"Submission exported to {path}\")\n","\n","make_submission(predictions)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"54Vsoe5zBDi4","executionInfo":{"status":"ok","timestamp":1734983282819,"user_tz":-60,"elapsed":553,"user":{"displayName":"L","userId":"12971862049250805533"}},"outputId":"78c9d34c-4921-4bfe-d045-3929ccc40763"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["   Pclass   Age  SibSp  Parch     Fare  Embarked  Sex_female  Sex_male  \\\n","0       3  34.5      0      0   7.8292         1         0.0       1.0   \n","1       3  47.0      1      0   7.0000         2         1.0       0.0   \n","2       2  62.0      0      0   9.6875         1         0.0       1.0   \n","3       3  27.0      0      0   8.6625         2         0.0       1.0   \n","4       3  22.0      1      1  12.2875         2         1.0       0.0   \n","5       3  14.0      0      0   9.2250         2         0.0       1.0   \n","6       3  30.0      0      0   7.6292         1         1.0       0.0   \n","7       2  26.0      1      1  29.0000         2         0.0       1.0   \n","8       3  18.0      0      0   7.2292         0         1.0       0.0   \n","9       3  21.0      2      0  24.1500         2         0.0       1.0   \n","\n","   Ticket_number  Ticket_item  \n","0         330911           15  \n","1         363272           15  \n","2         240276           15  \n","3         315154           15  \n","4        3101298           15  \n","5           7538           15  \n","6         330972           15  \n","7         248738           15  \n","8           2657           15  \n","9          48871            3  \n","[[3.000000e+00 3.450000e+01 0.000000e+00 0.000000e+00 7.829200e+00\n","  1.000000e+00 0.000000e+00 1.000000e+00 3.309110e+05 1.500000e+01]\n"," [3.000000e+00 4.700000e+01 1.000000e+00 0.000000e+00 7.000000e+00\n","  2.000000e+00 1.000000e+00 0.000000e+00 3.632720e+05 1.500000e+01]\n"," [2.000000e+00 6.200000e+01 0.000000e+00 0.000000e+00 9.687500e+00\n","  1.000000e+00 0.000000e+00 1.000000e+00 2.402760e+05 1.500000e+01]\n"," [3.000000e+00 2.700000e+01 0.000000e+00 0.000000e+00 8.662500e+00\n","  2.000000e+00 0.000000e+00 1.000000e+00 3.151540e+05 1.500000e+01]\n"," [3.000000e+00 2.200000e+01 1.000000e+00 1.000000e+00 1.228750e+01\n","  2.000000e+00 1.000000e+00 0.000000e+00 3.101298e+06 1.500000e+01]]\n","[0.03873766 0.02918731 0.01147026 0.6371232  0.820148  ]\n","[False False False  True  True]\n","[0, 0, 0, 1, 1]\n","Submission exported to /content/drive/MyDrive/2-folder/kaggle/titanic/submission.csv\n"]}]}]}