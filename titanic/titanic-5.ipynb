{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1qGdR53aHr0_sRTD9-o9Fd2hWU6tzulra","authorship_tag":"ABX9TyPR0sdODhwdUQT7wgq5+Y1j"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":7,"metadata":{"id":"pfmpgBmLwkvV","executionInfo":{"status":"ok","timestamp":1735585233028,"user_tz":-60,"elapsed":389,"user":{"displayName":"L","userId":"12971862049250805533"}}},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split\n","!cp /content/drive/MyDrive/2-folder/kaggle/df_utils.py /content/\n","import df_utils"]},{"cell_type":"code","source":["def preprocess(df):\n","    df = df.copy()\n","\n","    # def normalize_name(x):\n","    #     return \" \".join([v.strip(\",()[].\\\"'\") for v in x.split(\" \")])\n","\n","    def ticket_number(x):\n","        return x.split(\" \")[-1]\n","\n","    def ticket_item(x):\n","        items = x.split(\" \")\n","        if len(items) == 1:\n","            return \"NONE\"\n","        return \"_\".join(items[0:-1])\n","\n","    # df[\"Name\"] = df[\"Name\"].apply(normalize_name)\n","    df[\"Ticket_number\"] = df[\"Ticket\"].apply(ticket_number)\n","    df[\"Ticket_item\"] = df[\"Ticket\"].apply(ticket_item)\n","    return df"],"metadata":{"id":"H6Qg9Zrh1UwN","executionInfo":{"status":"ok","timestamp":1735585236318,"user_tz":-60,"elapsed":372,"user":{"displayName":"L","userId":"12971862049250805533"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["df_train = pd.read_csv('/content/drive/MyDrive/2-folder/kaggle/titanic/train.csv')\n","df_test = pd.read_csv('/content/drive/MyDrive/2-folder/kaggle/titanic/test.csv')\n","# print(df_train.head(5))\n","\n","df_train_x = preprocess(df_train)\n","df_train_x.Ticket_number = pd.to_numeric(df_train_x.Ticket_number, errors='coerce')\n","df_train_x = df_train_x.drop(['Ticket'], axis=1)\n","print(df_train_x.head(5))\n","\n","def prepare_df(df, max_unique = 0, skip_cols=None):\n","  df_copy = df.copy()\n","  for column in df_copy:\n","    if column in skip_cols:\n","      continue\n","    print(column)\n","    column_type = df_copy[column].dtype\n","    check_nan = df_copy[column].isnull().values.any()\n","    # print(f'check_nan = {check_nan}')\n","    if column_type == 'object':\n","        # print(f'The column {column} contains string data')\n","        unique = df_copy[column].nunique()\n","        # print(f'unique = {unique}')\n","        if unique > max_unique:\n","          df_copy = df_copy.drop([column], axis=1)\n","          continue\n","        if check_nan:\n","          df_utils.fill_with_mode(column, df_copy)\n","        df_copy = df_utils.one_hot_encoding(df_copy, column)\n","    else:\n","        # print(f'The column {column} does not contain string data')\n","        if check_nan:\n","          df_utils.fill_with_mean(column, df_copy)\n","  return df_copy\n","\n","df_train_x = prepare_df(df_train_x, 5, 'Survived')\n","\n","# ----------------------------------------------------------------\n","\n","y = df_train_x['Survived'].values\n","# print(y[0:5])\n","df_train_x = df_train_x.drop(['Survived'], axis=1)\n","\n","# normalize dataframe\n","# df_train_x=(df_train_x-df_train_x.mean())/df_train_x.std()\n","\n","X = df_train_x.values  #.astype(float)\n","# print(X[0:5])\n","\n","X_trainset, X_testset, y_trainset, y_testset = train_test_split(X, y, test_size=0.1, random_state=3)\n","print('Shape of X training set {}'.format(X_trainset.shape),'&',' Size of Y training set {}'.format(y_trainset.shape))\n","print('Shape of X test set {}'.format(X_testset.shape),'&','Size of y test set {}'.format(y_testset.shape))\n","\n","print(f\"X_trainset = {X_trainset.shape}\")\n","print(f\"X_testset = {X_testset.shape}\")\n","print(f\"y_trainset = {y_trainset.shape}\")\n","print(f\"y_testset = {y_testset.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ExCQRc-j1msz","executionInfo":{"status":"ok","timestamp":1735586332426,"user_tz":-60,"elapsed":364,"user":{"displayName":"L","userId":"12971862049250805533"}},"outputId":"2e2cd240-97d4-4dca-a7f5-2831ed85804d"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["   PassengerId  Survived  Pclass  \\\n","0            1         0       3   \n","1            2         1       1   \n","2            3         1       3   \n","3            4         1       1   \n","4            5         0       3   \n","\n","                                                Name     Sex   Age  SibSp  \\\n","0                            Braund, Mr. Owen Harris    male  22.0      1   \n","1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n","2                             Heikkinen, Miss. Laina  female  26.0      0   \n","3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n","4                           Allen, Mr. William Henry    male  35.0      0   \n","\n","   Parch     Fare Cabin Embarked  Ticket_number Ticket_item  \n","0      0   7.2500   NaN        S        21171.0         A/5  \n","1      0  71.2833   C85        C        17599.0          PC  \n","2      0   7.9250   NaN        S      3101282.0    STON/O2.  \n","3      0  53.1000  C123        S       113803.0        NONE  \n","4      0   8.0500   NaN        S       373450.0        NONE  \n","PassengerId\n","Pclass\n","Name\n","Sex\n","Age\n","SibSp\n","Parch\n","Fare\n","Cabin\n","Embarked\n","Ticket_number\n","Ticket_item\n","Shape of X training set (801, 12) &  Size of Y training set (801,)\n","Shape of X test set (90, 12) & Size of y test set (90,)\n","   PassengerId  Pclass   Age  SibSp  Parch     Fare  Ticket_number  \\\n","0            1       3  22.0      1      0   7.2500        21171.0   \n","1            2       1  38.0      1      0  71.2833        17599.0   \n","2            3       3  26.0      0      0   7.9250      3101282.0   \n","3            4       1  35.0      1      0  53.1000       113803.0   \n","4            5       3  35.0      0      0   8.0500       373450.0   \n","\n","   Sex_female  Sex_male  Embarked_C  Embarked_Q  Embarked_S  \n","0         0.0       1.0         0.0         0.0         1.0  \n","1         1.0       0.0         1.0         0.0         0.0  \n","2         1.0       0.0         0.0         0.0         1.0  \n","3         1.0       0.0         0.0         0.0         1.0  \n","4         0.0       1.0         0.0         0.0         1.0  \n","X_trainset_t = torch.Size([801, 12])\n","X_testset_t = torch.Size([90, 12])\n","y_trainset_t = torch.Size([801])\n","y_testset_t = torch.Size([90])\n"]}]},{"cell_type":"code","source":["# Dummy data (replace with real dataset)\n","# 100 samples, 10 features each\n","# X = torch.randn(100, 10)\n","# y = torch.randint(0, 3, (100,))  # 3 classes: 0, 1, 2\n","# print(X.shape)\n","# print(y.shape)\n","\n","X_trainset_t=X_trainset_t.type(torch.float32)\n","X_testset_t=X_testset_t.type(torch.float32)\n","y_trainset_t=y_trainset_t.type(torch.float32)\n","y_testset_t=y_testset_t.type(torch.float32)\n","\n","X = X_trainset_t\n","y = y_trainset_t\n","\n","print(X_trainset_t.dtype)\n","print(X_trainset_t.shape)\n","print(y_trainset_t.dtype)\n","print(y_trainset_t.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RxVb8gqBxHla","executionInfo":{"status":"ok","timestamp":1734979669082,"user_tz":-60,"elapsed":240,"user":{"displayName":"L","userId":"12971862049250805533"}},"outputId":"d40d2bf2-81dd-4bea-d622-8635b3a18ac7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.float32\n","torch.Size([639, 10])\n","torch.float32\n","torch.Size([639])\n"]}]},{"cell_type":"code","source":["# X = torch.randn(100, 10)  # Features\n","# y = torch.randint(0, 2, (100,)).float()  # Binary labels (0 or 1)\n","# print(X.shape)\n","# print(X.dtype)\n","# print(y.shape)\n","# print(y.dtype)\n","X = X_trainset_t\n","y = y_trainset_t\n","\n","# Dataset and DataLoader\n","dataset = TensorDataset(X, y)\n","dataloader = DataLoader(dataset, batch_size=30, shuffle=True)\n","\n","# Define the model\n","class BinaryClassifier(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(BinaryClassifier, self).__init__()\n","        self.fc1 = nn.Linear(input_size, hidden_size)\n","        self.relu = nn.ReLU()\n","        self.fc2 = nn.Linear(hidden_size, 1)\n","        self.sigmoid = nn.Sigmoid()  # Output probabilities\n","\n","    def forward(self, x):\n","        x = self.fc1(x)\n","        x = self.relu(x)\n","        x = self.fc2(x)\n","        x = self.sigmoid(x)\n","        return x\n","\n","# Initialize the model, loss, and optimizer\n","input_size = 10\n","hidden_size = 32\n","\n","model = BinaryClassifier(input_size, hidden_size)\n","criterion = nn.BCELoss()  # Binary Cross-Entropy Loss\n","optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n","\n","# Training loop\n","num_epochs = 100\n","\n","for epoch in range(num_epochs):\n","    for batch in dataloader:\n","        inputs, labels = batch\n","\n","        # Forward pass\n","        outputs = model(inputs).squeeze()  # Remove extra dimension\n","        # print(outputs.shape)\n","        # print(labels.shape)\n","        loss = criterion(outputs, labels)\n","\n","        # Backward pass\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2wc1TfRyEI-5","executionInfo":{"status":"ok","timestamp":1734979673053,"user_tz":-60,"elapsed":3983,"user":{"displayName":"L","userId":"12971862049250805533"}},"outputId":"e385f297-b8bb-4eca-ed45-c0f3068e02f8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/100], Loss: 0.7188\n","Epoch [2/100], Loss: 0.5303\n","Epoch [3/100], Loss: 0.6985\n","Epoch [4/100], Loss: 0.4456\n","Epoch [5/100], Loss: 0.6074\n","Epoch [6/100], Loss: 0.2632\n","Epoch [7/100], Loss: 0.5128\n","Epoch [8/100], Loss: 0.6000\n","Epoch [9/100], Loss: 0.2767\n","Epoch [10/100], Loss: 0.1942\n","Epoch [11/100], Loss: 0.5115\n","Epoch [12/100], Loss: 0.5976\n","Epoch [13/100], Loss: 0.7625\n","Epoch [14/100], Loss: 0.4983\n","Epoch [15/100], Loss: 0.3771\n","Epoch [16/100], Loss: 0.2547\n","Epoch [17/100], Loss: 0.2872\n","Epoch [18/100], Loss: 0.7483\n","Epoch [19/100], Loss: 0.4178\n","Epoch [20/100], Loss: 0.8189\n","Epoch [21/100], Loss: 0.3171\n","Epoch [22/100], Loss: 0.4610\n","Epoch [23/100], Loss: 0.6929\n","Epoch [24/100], Loss: 0.4097\n","Epoch [25/100], Loss: 0.8370\n","Epoch [26/100], Loss: 0.8206\n","Epoch [27/100], Loss: 0.3101\n","Epoch [28/100], Loss: 0.2841\n","Epoch [29/100], Loss: 0.5757\n","Epoch [30/100], Loss: 0.3653\n","Epoch [31/100], Loss: 0.4250\n","Epoch [32/100], Loss: 0.3185\n","Epoch [33/100], Loss: 0.6271\n","Epoch [34/100], Loss: 0.3745\n","Epoch [35/100], Loss: 0.4250\n","Epoch [36/100], Loss: 0.3956\n","Epoch [37/100], Loss: 0.4966\n","Epoch [38/100], Loss: 0.2570\n","Epoch [39/100], Loss: 0.6367\n","Epoch [40/100], Loss: 0.4763\n","Epoch [41/100], Loss: 0.1899\n","Epoch [42/100], Loss: 0.3465\n","Epoch [43/100], Loss: 0.0602\n","Epoch [44/100], Loss: 0.7279\n","Epoch [45/100], Loss: 0.2090\n","Epoch [46/100], Loss: 0.3281\n","Epoch [47/100], Loss: 0.3369\n","Epoch [48/100], Loss: 0.2307\n","Epoch [49/100], Loss: 0.2623\n","Epoch [50/100], Loss: 0.2878\n","Epoch [51/100], Loss: 0.2750\n","Epoch [52/100], Loss: 0.4195\n","Epoch [53/100], Loss: 0.3931\n","Epoch [54/100], Loss: 0.2880\n","Epoch [55/100], Loss: 0.3172\n","Epoch [56/100], Loss: 0.2141\n","Epoch [57/100], Loss: 0.2547\n","Epoch [58/100], Loss: 0.3082\n","Epoch [59/100], Loss: 0.2532\n","Epoch [60/100], Loss: 0.4183\n","Epoch [61/100], Loss: 0.2407\n","Epoch [62/100], Loss: 0.1758\n","Epoch [63/100], Loss: 0.1654\n","Epoch [64/100], Loss: 0.1932\n","Epoch [65/100], Loss: 0.3092\n","Epoch [66/100], Loss: 0.3089\n","Epoch [67/100], Loss: 0.2432\n","Epoch [68/100], Loss: 0.3331\n","Epoch [69/100], Loss: 0.3063\n","Epoch [70/100], Loss: 0.7080\n","Epoch [71/100], Loss: 0.1557\n","Epoch [72/100], Loss: 0.7480\n","Epoch [73/100], Loss: 0.5273\n","Epoch [74/100], Loss: 0.3065\n","Epoch [75/100], Loss: 0.4657\n","Epoch [76/100], Loss: 0.1371\n","Epoch [77/100], Loss: 0.2667\n","Epoch [78/100], Loss: 0.4118\n","Epoch [79/100], Loss: 0.5672\n","Epoch [80/100], Loss: 0.2257\n","Epoch [81/100], Loss: 0.4936\n","Epoch [82/100], Loss: 0.3525\n","Epoch [83/100], Loss: 0.8298\n","Epoch [84/100], Loss: 0.2509\n","Epoch [85/100], Loss: 0.2175\n","Epoch [86/100], Loss: 0.6051\n","Epoch [87/100], Loss: 0.5217\n","Epoch [88/100], Loss: 0.1488\n","Epoch [89/100], Loss: 0.2631\n","Epoch [90/100], Loss: 0.3915\n","Epoch [91/100], Loss: 0.2645\n","Epoch [92/100], Loss: 0.4170\n","Epoch [93/100], Loss: 0.4349\n","Epoch [94/100], Loss: 0.5989\n","Epoch [95/100], Loss: 0.3895\n","Epoch [96/100], Loss: 0.1772\n","Epoch [97/100], Loss: 0.2071\n","Epoch [98/100], Loss: 0.2703\n","Epoch [99/100], Loss: 0.1771\n","Epoch [100/100], Loss: 0.4605\n"]}]},{"cell_type":"code","source":["# Evaluation (Example)\n","model.eval()  # Set to evaluation mode\n","with torch.no_grad():\n","    # test_input = torch.randn(1, input_size)  # Example input\n","    print(X_testset_t.dtype)\n","    print(X_testset_t.shape)\n","    test_output = model(X_testset_t)\n","    test_output = test_output.squeeze()\n","    print(test_output.shape)\n","    print(test_output[:5])\n","    # predicted_class = 1 if test_output.item() > 0.5 else 0\n","    # print(f\"Predicted class: {predicted_class}\")\n","    test_output = test_output > 0.5\n","    print(test_output[:5])\n","    test_output = test_output.int()\n","    print(test_output[:5])\n","\n","    y_testset_t = y_testset_t.int()\n","    print(y_testset_t.shape)\n","    print(y_testset_t[:5])\n","\n","    test_result = test_output == y_testset\n","    print(test_result.shape)\n","    print(test_result[:5])\n","\n","    test_result = test_result.int()\n","    print(test_result[:5])\n","    s = test_result.sum().item()\n","    l = test_result.shape[0]\n","    accuracy = round(s/l, 2)\n","    print(accuracy)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y8Bs7I-CJPYI","executionInfo":{"status":"ok","timestamp":1734979673053,"user_tz":-60,"elapsed":13,"user":{"displayName":"L","userId":"12971862049250805533"}},"outputId":"57732135-bf69-44a6-87af-a904708900c2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.float32\n","torch.Size([71, 10])\n","torch.Size([71])\n","tensor([0.0952, 0.1420, 0.9081, 0.8706, 0.0984])\n","tensor([False, False,  True,  True, False])\n","tensor([0, 0, 1, 1, 0], dtype=torch.int32)\n","torch.Size([71])\n","tensor([0, 1, 1, 1, 0], dtype=torch.int32)\n","torch.Size([71])\n","tensor([ True, False,  True,  True,  True])\n","tensor([1, 0, 1, 1, 1], dtype=torch.int32)\n","0.86\n"]}]},{"cell_type":"code","source":["df_test = pd.read_csv('/content/drive/MyDrive/2-folder/kaggle/titanic/test.csv')\n","#print(df_train.head(10))\n","\n","df_test_x = df_test.drop(['PassengerId', 'Name', 'Cabin'], axis=1)\n","\n","# Categorical values to numeric\n","df_test_x = df_utils.one_hot_encoding(df_test_x, \"Sex\")\n","label_encoder = preprocessing.LabelEncoder()\n","df_test_x['Embarked']= label_encoder.fit_transform(df_test_x['Embarked'])\n","\n","df_test_x = preprocess(df_test_x)\n","df_test_x = df_test_x.drop(['Ticket'], axis=1)\n","df_test_x['Ticket_item']= label_encoder.fit_transform(df_test_x['Ticket_item'])\n","df_test_x.Ticket_number = pd.to_numeric(df_test_x.Ticket_number, errors='coerce')\n","\n","# Fix NaN\n","# print(df_test_x.isna().any())\n","df_utils.fill_with_mean(\"Age\", df_test_x)\n","df_utils.fill_with_mean(\"Fare\", df_test_x)\n","\n","# print(f\"df_test_x.shape[0] = {df_test_x.shape[0]}\")\n","print(df_test_x.head(10))\n","\n","# normalize dataframe\n","df_test_x=(df_test_x-df_test_x.mean())/df_test_x.std()\n","# print(df_test_x.head(10))\n","X_testset_t = torch.from_numpy(df_test_x.values)\n","X_testset_t=X_testset_t.type(torch.float32)\n","# print(X_testset_t.dtype)\n","# print(X_testset_t.shape)\n","\n","model.eval()  # Set to evaluation mode\n","with torch.no_grad():\n","    # test_input = torch.randn(1, input_size)  # Example input\n","    print(X_testset_t.dtype)\n","    print(X_testset_t.shape)\n","    print(X_testset_t[5:])\n","    test_output = model(X_testset_t)\n","    test_output = test_output.squeeze()\n","    print(test_output.shape)\n","    print(test_output[:5])\n","    test_output = test_output > 0.5\n","    print(test_output[:5])\n","    test_output = test_output.int()\n","    print(test_output[:5])\n","    y_ = test_output.numpy()\n","    print(y_[:5])\n","\n","predictions = pd.DataFrame({\n","        \"PassengerId\": df_test[\"PassengerId\"],\n","        \"Survived\": y_\n","    })\n","\n","def make_submission(predictions):\n","    path=\"/content/drive/MyDrive/2-folder/kaggle/titanic/submission.csv\"\n","    predictions.to_csv(path, index=False)\n","    print(f\"Submission exported to {path}\")\n","\n","make_submission(predictions)"],"metadata":{"id":"xqhU10N-Rp4s","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1734979673054,"user_tz":-60,"elapsed":11,"user":{"displayName":"L","userId":"12971862049250805533"}},"outputId":"6476cdbc-dded-4e49-fedb-c547f83fd52c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["   Pclass   Age  SibSp  Parch     Fare  Embarked  Sex_female  Sex_male  \\\n","0       3  34.5      0      0   7.8292         1         0.0       1.0   \n","1       3  47.0      1      0   7.0000         2         1.0       0.0   \n","2       2  62.0      0      0   9.6875         1         0.0       1.0   \n","3       3  27.0      0      0   8.6625         2         0.0       1.0   \n","4       3  22.0      1      1  12.2875         2         1.0       0.0   \n","5       3  14.0      0      0   9.2250         2         0.0       1.0   \n","6       3  30.0      0      0   7.6292         1         1.0       0.0   \n","7       2  26.0      1      1  29.0000         2         0.0       1.0   \n","8       3  18.0      0      0   7.2292         0         1.0       0.0   \n","9       3  21.0      2      0  24.1500         2         0.0       1.0   \n","\n","   Ticket_number  Ticket_item  \n","0         330911           15  \n","1         363272           15  \n","2         240276           15  \n","3         315154           15  \n","4        3101298           15  \n","5           7538           15  \n","6         330972           15  \n","7         248738           15  \n","8           2657           15  \n","9          48871            3  \n","torch.float32\n","torch.Size([418, 10])\n","tensor([[ 0.8724, -1.2879, -0.4989,  ...,  0.7550, -0.4184, -0.0728],\n","        [ 0.8724, -0.0216, -0.4989,  ..., -1.3213,  0.1320, -0.0728],\n","        [-0.3154, -0.3382,  0.6163,  ...,  0.7550, -0.0079, -0.0728],\n","        ...,\n","        [ 0.8724,  0.6512, -0.4989,  ...,  0.7550,  4.8459,  2.5942],\n","        [ 0.8724,  0.0000, -0.4989,  ...,  0.7550,  0.1802, -0.0728],\n","        [ 0.8724,  0.0000,  0.6163,  ...,  0.7550, -0.4266, -0.0728]])\n","torch.Size([418])\n","tensor([0.0720, 0.5550, 0.0564, 0.1022, 0.7703])\n","tensor([False,  True, False, False,  True])\n","tensor([0, 1, 0, 0, 1], dtype=torch.int32)\n","[0 1 0 0 1]\n","Submission exported to /content/drive/MyDrive/2-folder/kaggle/titanic/submission.csv\n"]}]}]}